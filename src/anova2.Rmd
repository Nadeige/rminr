---
title: "Evidence, part 3"
author: "Andy Wills"
output: html_document
---

```{r setup, include=FALSE}
## DEVELOPERS: Uncomment one option, as appropriate

## Show only commands.
## knitr::opts_chunk$set(echo = TRUE, message = FALSE, results='hide', fig.keep = 'none', comment=NA)

## Show commands and putout.
knitr::opts_chunk$set(echo = TRUE, comment=NA, cache = TRUE)


```

For parts 1 and 2 of this worksheet, see the [Absolute Beginners' Guide to R](evidence.html), and the [Evidence, part 2](anova1.html) worksheet.

# Contents

- [Introduction](#intro)

- [Getting started](#started)

<a name="into"></a>

# Introduction

In the [Evidence, part 2](anova1.html) worksheet, we used a Bayesian within-subjects ANOVA to test for an effect of _word-picture congruence_ in word naming. Specifically, we looked at an experiment in which people had to read words out loud as quickly as possible. On some trials, those words were accompanied by _congruent_ pictures (e.g. the word 'dog' and a picture of a dog). On other trials, the words were accompanied by an _incongruent_ picture (e.g. the word 'dog' and a picture of a pencil). Participants were instructed to ignore the pictures ... but we found they could not do so. Reaction times were longer for _incongruent_ trials than _congruent_ trials, and there was substantial Bayesian evidence for that difference. In fact the Bayes Factor was over 40 million ($BF = 4.4 \times 10^{7}$). 

These kinds of _congruency_ effects are well known in psychology, and demonstrating them once again was not the main point of this experiment. Instead, the researchers were interested in the idea that learning how to meditate might increase your ability to attend to just the relevant aspects of a task. If this were true, the _congruency effect_ would be smaller for those trained in meditation than for those who did not receive such training. In other words, the difference between the incongruent reaction time and the congruent reaction time would be smaller for meditators than non-meditators.

To test this idea, the experimenters randomly allocated 140 people to a week-long meditation training course, while another 140 people were randomly allocated to a no-training control condition. All these people then did a word-naming task. In this worksheet, we'll look at how to analyze data from this kind of experiment.

# Getting started

This worksheet uses the same _git_ repository as the [preprocessing]() and [evidence, part 2]() worksheets. Go back to the R project that contains this now.

Now, make sure you have loaded the data, and have loaded the R packages you need:

```{r started, message=FALSE}
library(tidyverse)
library(BayesFactor, quietly = TRUE)
words <- read_csv("wordnaming2.csv")
```

Take a look back at the [description of this data frame]() to remind yourself what it contains.

# Filtering

In the full experiment, there were actually three between-subject conditions: meditation training, no training ("control"), and relaxation training. In this first example, we're only going to look at the first two of those conditions: `meditate` and `control`. So

**WRITE A COMMAND** that removes the participants in `relax` condition from the `words` data frame. It is the `medit` column of that data frame that contains the information about which condition each participant was in. Use the `filter` command to do this, and put the result into a new data frame called `MCwords`. As the `filter` command sets which data to _keep_, you may find the `!=` operator useful here -- it means 'not equal to'. If you need to revise how to do this, take a look back at the [preprocessing]() worksheet.

```{r filter, echo=FALSE}
MCwords <- words %>% filter(medit != "relax")
```

_EXPECTED OUTPUT_: A new data framce called `MCwords` will be in your _Environment_. It will have 25,200 rows and 10 columns.

The full experiment also included three types of trial: congruent, incongruent, and neutral. The first two are described above. In _neutral_ trials, the word is presented alone, without a picture. In this first example, we're only going to look at the congruent and incongruent trials. So

**WRITE A COMMAND** that removes the `neutral` trials from the `MCwords` data frame, and puts the filtered data into a new data frame called `MCwordsCI`. It is the `congru` column that contains information about trial type.

```{r filter2, echo=FALSE}
MCwordsCI <- MCwords %>% filter(congru != "neutral")
```

_EXPECTED OUTPUT_: A new data frame called `MCwordsCI` will be in your _Environment_. It will have 16,800 rows and 10 columns.

# Summarising

The data frame `MCwordsCI` is still very long, because it contains every trial for every participant. What we want to know, for each participant, is their mean reaction time on congruent and incongruent trials (i.e. two numbers per person). So

**WRITE A COMMAND** to _group_ the data by participant ID (`subj`), trial type (`congru`) and between-subjects condition (i.e. meditation versus control, `medit`). Get the mean reaction times using the `summarise` command, and put this summarized data into a new data frame called `MCwordsCIsum`. If you need a reminder of how to group and summarise data, take a look at the [preprocessing](preproc.html#filter) worksheet. The column containing the RT data in this new data frame will need to have the name `rt`, because we assume this later on. You can set the column name within the `summarise` command. For example, `summarise(acc = mean(acc))` takes the mean of the column `acc` and puts the answer into a column called `acc` in your new data frame.

```{r sum1, echo=FALSE}
MCwordsCIsum <-
    MCwordsCI %>% group_by(subj, medit, congru) %>% summarise(rt = mean(rt))
```

_EXPECTED OUTPUT_: A new data frame called `MCwordsCIsum` will be in your _Environment_. It will have 560 rows and 4 columns. There will be two rows for each participant, one for incongruent trials, one for congruent trials. Each participant will be identified as being in either the `meditate` or `control` condition. 

# Difference scores: Pivoting and mutating

Exactly as we did in the [Evidence, part 2]() worksheet, we can now use the `pivot_wider` and `mutate` commands to work out a _difference score_ for each participant. This gives us the size of the _congruency effect_ for that participant, i.e. how much more time they take on incongruent trials than congruent trials (on average). 

```{r diffscore}
medidiff <- MCwordsCIsum %>%
    pivot_wider(names_from = congru, values_from = rt) %>%
    mutate(diff = incong - cong)
```

Take a look at the `medidiff` data frame in your _Environment_. You'll see there is now one row for each participant, with a difference score in the `diff` column. You may also notice that, in the `meditate` condition, there are about an equal number of positive and negative differences. Things look different in the `control` condition, where positive scores are much more likely than negative scores. So, on a quick look, it seems like the congruency effect might be (on average) smaller for those with meditation training.

# Density plot of differences

We can look at this more closely using a density plot, as we have on many previous occasions:

```{r diffplot}
medidiff %>% ggplot(aes(diff, colour=medit)) +
    geom_density(aes(y=..scaled..)) +
    geom_vline(xintercept = 0, colour = 'purple')
```

This plot is very much like the one we drew in [Evidence, part 2](anova1.html#densediff), and the curve for the control condition is identical. So, as before, we can see that in the control condition, most _congruency scores_ are positive, although there is of course a range (from about -200 to +300 ms). 

The new part of this graph is that we also have a curve for the meditation condition. It is the `colour=medit` part of the command that causes this to happen - it draws one curve for each _level_ of the `medit` factor, and gives each a different colour.

We can see that the curve for the `meditate` condition is approximately centered on zero. In other words, on average, there is no congruency effect after meditation training. 

# Bayesian ANOVA (between-subjects)

So, there appears to be an effect of meditation on the congruency score, but how good is the evidence for that claim? We can use a between-subjects Bayesian ANOVA to work this out. So

**WRITE SOME COMMANDS** that use the `medidiff` data frame to perform a between-subjects Bayesian ANOVA (`anovaBF`) on the effect of group (i.e. meditation versus control, found in the `medit` column) on the congruency score (found in the `diff` column). Don't forget to tell R which columns are _factors_, using the `factor` command. If you need to revise how to do this, take a look back at the [Evidence, part 2](anova1.html#factors) worksheet.

_EXPECTED OUTPUT_: You should get the following output:

```{r easy, echo=FALSE}
medidiff$medit <- factor(medidiff$medit)
anovaBF(formula = diff ~ medit, data = data.frame(medidiff))
```

The intepretation of this output is the same as before. The key figure here is the Bayes Factor, which is close to 5000 on this occasion. This is very substantial evidence in favour of a difference between conditions. If, prior to seeing this analysis, you thought it was about 50:50 whether meditation would affect attention in this experiment or not, this Bayes Factor tells you that you should now think that it is about 5000 times more likely there is an effect (in this experiment) than there isn't. 

# "Interaction" as difference of differences

To summarise, we've found that the congruency effect is smaller after meditation training than after no training. The congruency effect is, as we have discussed, calculated as a difference between two average reaction times - the reaction time on incongruent trials minus the reaction time on congruent trials. This difference is smaller after meditation training than after no training. So, the results of this experiment can be described as a _difference of differences_. The RT difference is smaller for meditation than for control particiapnts. 

The phrase _difference of differences_ is a bit clumsy, so we often use another, jargon, word for it. We say that the results of this experiment show an _interaction_ between trial type (congruent, incongruent) and training type (meditation, control). This is just another way of saying the size of the difference between trial types is affected by training type. This is what our density plot of differences (above) shows.

# Interactions and main effects

We normally talk about interactions in the context of experiments that have a _factorial_ design. An experiment has a _factorial_ design if more than one _factor_ is manipulated, and all combinations of those factors are tested. For example, the meditation and attention experiment we've been looking at has a factorial design. It has two factors. The first factor is type of pre-training (meditation versus none). The second factor is type of test trial (congruent versus incongruent). The experiment has a _factorial_ design because we have data for all four combinations of trial types (congruent, incongruent) and pre-training conditions (meditation, none). 

With a two-factor experiment like this one, there are three basic analysis questions we can ask:

1. Averaging over different trial types (congruent, incongruent), does meditation affect reaction times? This is known as the **main effect** of meditation.

2. Averaging over different pre-training conditions (meditation, control), does trial type (congruent, incongruent) affect reaction times? This is known as the **main effect** of trial type (or the **main effect** of congruency, in this case).

3. Do these two main effects _interact_? So, for example, is the congruency effect larger in the meditation condition than the control condition? This is known as the **interaction**. 

For each of these questions, the answer can be either 'yes' or 'no'. If we don't have enough data, the answer could also be 'we don't know', but we'll come back to that later. So, when we analyze a two-factor experiment, there are eight different results we could get:

| Main effect: meditation | Main effect: congruence | Interaction |
| ----------------------- | ----------------------- | ----------- |
| no                      | no                      | no          |
| no                      | no                      | yes         |
| no                      | yes                     | no          |
| no                      | yes                     | yes         |
| yes                     | no                      | no          |
| yes                     | no                      | yes         |
| yes                     | yes                     | no          |
| yes                     | yes                     | yes         |

# Exercise

Below, you will find eight graphs. Each shows four mean reaction times - mean reaction time for incongruent and congruent trials for both the meditation condition and the control condition. The goal is to decide, for each graph, whether there is a main effect of meditation, whether there is a main effect of congruence, and whether there is an interaction. 



```{r hard}
MCwordsCIsum$subj <- factor(MCwordsCIsum$subj)
MCwordsCIsum$medit <- factor(MCwordsCIsum$medit)
MCwordsCIsum$congru <- factor(MCwordsCIsum$congru)

bf <- anovaBF(formula = rt ~ medit*congru + subj,
              data = data.frame(MCwordsCIsum), whichRandom = "subj")
bf
```
___



This material is distributed under a [Creative Commons](https://creativecommons.org/) licence. CC-BY-SA 4.0. 


