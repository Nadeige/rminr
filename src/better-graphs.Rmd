---
title: "Better graphs"
author: "Andy Wills, Paul Sharpe"
output:
  html_document:
    highlight: pygment
---

```{r setup, include=FALSE}
## DEVELOPERS: Uncomment one option, as appropriate

## Show only commands.
## knitr::opts_chunk$set(echo = TRUE, message = FALSE, results='hide', fig.keep = 'none', comment=NA)

## Show commands and output.
knitr::opts_chunk$set(echo = TRUE, comment=NA)
library(pander)
```

# Contents

* [Introduction](#intro)
* [Meaningful labels](#labels)
* [Journal styling](#style)
* [High-quality output](#hq)
* [Choosing a graph for your data](#choosing)
* [Within participants data](#within)
    + [One factor](#w-1x3)
    + [Two factors](#w-2x2)
* [Between participants data](#between)
    + [One factor, two levels](#b-1x2)
    + [One factor, four levels](#b-1x4)
* [Mixed (within-between) data](#mixed)
* [Pairs plot](#pairs)

<a name = "intro"></a>

# Introduction

In this worksheet, we'll look at how to produce publication-quality graphs in R. We start with an example from a previous worksheet. 

In the exercise for the [within-subject differences](anova1.html#densediff) worksheet, we produced a density plot of the within-subject differences in reaction time for congruent versus incongruent trials. Let's pick up where we left off. Go back to your `rminr-data` project, and open up the R file you used for this exercise. If you didn't complete that exercise, or can't find the file, you can get a copy [here](densediff.R)

```{r init, message=FALSE, echo=FALSE}
rm(list = ls()) # clear the environment
library(tidyverse)
words <- read_csv("wordnaming2.csv")
wordctrl <- words %>% filter(medit == "control")
wordctrlCI <- wordctrl %>% filter(congru != "neutral")
wordctrlCIsum <- wordctrlCI %>% group_by(subj, congru) %>% summarise(rt = mean(rt))
ctrl <- wordctrlCIsum %>% pivot_wider(names_from = congru, values_from = rt)
ctrldiff <- ctrl %>% mutate(diff = incong - cong)
```

After some preprocessing, the graphing command we used in that exercise was:

```{r graph}
ctrldiff %>% ggplot(aes(diff)) +
    geom_density(aes(y=..scaled..)) +
    geom_vline(xintercept = 0, colour = 'red')
```

This graph looks OK, but would need some improvement before including in a report or journal article. Here are the steps of this makeover.

<a name = "labels"></a>

# Meaningful labels

The first thing to do is change the axis labels to something a bit more human readable. We use the `xlab` and `ylab` commands for this. We covered these commands previously in the [Absolute Beginners' guide](exploring-incomes.html#custom-graphs):

```{r graph2}
ctrldiff %>% ggplot(aes(diff)) +
    geom_density(aes(y=..scaled..)) +
    geom_vline(xintercept = 0, colour = 'red') +
    xlab("Incongruent RT - Congruent RT (ms)") +
    ylab("Scaled density")
```

<a name = "style"></a>

# Journal styling

The default styling for `ggplot` is different to what is preferred in most psychology journals. Fortunately, we can use Tina Seabrooke's `theme_APA` to correct this. You'll find the code in the same _git_ repository as the data, so all you need to do is load in her code:

```{r source}
source("themeapa.R")
```

and then add it as a theme to your graph (much as you have used `theme_bw` in the past):

```{r graph3}
ctrldiff %>% ggplot(aes(diff)) +
    geom_density(aes(y=..scaled..)) +
    geom_vline(xintercept = 0, colour = 'red') +
    xlab("Incongruent RT - Congruent RT (ms)") +
    ylab("Scaled density") +
    theme_APA
```

<a name = "hq"></a>

# High-quality output

If you are writing a report or journal article, it's generally a bad idea to screenshot your graphs, and it's also generally a bad idea to use the _export_ functionality within Rstudio. This is because both of these options produce graphics that are not high enough quality for publication.

To produce high-quality output, you should first create an object for your graph, much as we created an [object for the output of analysis](anova3.html#bfact).

```{r graph4}
dgraph <- ctrldiff %>% ggplot(aes(diff)) +
    geom_density(aes(y=..scaled..)) +
    geom_vline(xintercept = 0, colour = 'red') +
    xlab("Incongruent RT - Congruent RT (ms)") +
    ylab("Scaled density") +
    theme_APA
dgraph
```

We can now use the `ggsave` command to save a high-quality version of that graph:

```{r ggsave}
ggsave(filename = "fig1.pdf", plot = dgraph, units = "cm", width = 15, height = 10)
```

## Explanation of command

`filename = "fig1.pdf"` - Save the graph as _fig1.pdf_. Try to use PDF where possible, because it produces the best quality output and the smallest file size. However, if you're unfortunate enough to be using a wordprocessor than cannot import PDF graphs (e.g. Microsoft Word) then you can use PNG format instead. You do this by changing the filename, e.g. `filename = "fig1.png"`. If you send your paper to a journal for consideration, they will also require the PDF version of your graphs as a separate attachement, as PNG files are generally not good enough for professional publications. For most internal reports (and university coursework), PNG is generally good enough.

`plot = dgraph` - Use the object called `dgraph` as the graph you want to save.

`units = "cm"` - The following commands will set the size of the graph; this command says what units these are in. You usually want to use "cm" (centimetres) but if you live in a country that hasn't adopted the metric system, you can use "in" (inches) instead. 

`width = 15` - The graph (including border etc.) should be 15 units wide (the units in this case being centimetres)

`height = 10` - The graph (including border etc.) should be 10 units high (centimetres in this case). 

## Explanation of output

A file called _fig1.pdf_ will have appeared in your _Files_ window in RStudio. You can export this in the [usual way](using-projects.html#download).

<a name="choosing"></a>

# Choosing a graph for your data

A graph should visually describe patterns in data that would otherwise be difficult to communicate. Choosing and configuring the most appropriate graph for you data, will depend on what you want to communicate to your reader. In practice, making this decision often involves trying out different types of graph, and the elements used to build them. You might generate new ideas for graphs after you have analysed you data and begun to interpret the results.

These subjective aspects make it difficult to provide hard and fast rules for the type of plot you should choose, and the elements that it should contain. A general piece of advice is to carefully consider the best way to represent the centre (often the mean), and distribution of your data. We present some suggestions for plotting different types of data in the following sections.

As a side note, a common criticism of student projects is that results sections don't include a graph, and appendices often contain lots of graphs which don't really contribute to the report. You can overcome this by learning to experiment with different with different ways of plotting your data. When you've found a graph that contributes to the argument you're trying to make, be confident and include it in your results section!

<a name="within"></a>

# Within participants data

We'll start by producing some graphs for within participants data.

<a name="w-1x3"></a>

## One factor

Our first example uses data from [an undergraduate student experiment on the Perruchet Effect](awdiss.html).

```{r perruchet-data, message=FALSE, class.source = 'numberLines lineAnchors'}
lvl.sum <- read_csv('going-further/perruchet-preproc.csv')
mdata  <- lvl.sum %>% group_by(level) %>%
  summarise(lcval = mean(lcval), expect = mean(expect))
```

We want to plot a graph for a single, within participants factor. The simplest graph we could produce here would be to just plot the three means, but this wouldn't really add anything to the means that were presented earlier in the report. 

Generally, when we graph data from psychology experiments, we try to give an indication of the variability between participants - is everyone exactly like the mean, or do people differ? One common way of doing this it to plot some kind of 'error bar'; for example, as shown in Figure 1 of  [McAndrew et al. (2012)](https://www.researchgate.net/profile/IPL_Mclaren/publication/221752843_Dissociating_Expectancy_of_Shock_and_Changes_in_Skin_Conductance_An_Investigation_of_the_Perruchet_Effect_Using_an_Electrodermal_Paradigm/links/0a85e53c10b74f291a000000.pdf). McAndrew et al., are not clear how they calculated these bars, but it's quite likely that they are the standard errors, considering each Level separately -- because this is the most common plot of this type. Such error bars are not particularly informative because, for example, they represent the variability _between_ participants at each Level, when the experiment is a _repeated measures_ design and so it is the variability of the trends across Level that is most relevant.

In this project, we instead plot one line for each participant, and then overlay this with the means to emphasize the overall trend.

```{r perruchet, message=FALSE, class.source = 'numberLines lineAnchors'}
### Create a blank plot
base  <- ggplot()

### Add a line for each participant
lns  <- geom_line(aes(x=level, y=expect, group=subj, colour=subj),
                  data = lvl.sum, alpha = .25)

### Add a mean line
mline  <- geom_line(aes(x=level, y=expect), data = mdata, colour="black")
mdot  <- geom_point(aes(x=level, y=expect), data = mdata, colour="black")

### Combine plots, tidy up x and y axis labels, and apply APA theme
eplot <- base + lns + mline + mdot + xlab("Level") +
    ylab("Expectancy rating") + ylim(1,5) +
    scale_x_continuous(breaks = c(1,2,3)) +
    theme_APA + theme(legend.position="none")
eplot
```

### Explanation of commands

### Explanation of plot

From this plot, it's clear that: (a) the overall trend is downwards, (b) most but not all participants individually show this trend, and (c) there is some variation in the absolute ratings people use.

<a name="w-2x2"></a>

## Two factors

Our next example is from an experiment with two factors. Participants were trained to associate two screen colours with pictures of two different food rewards. At test, they saw pairs of screen colours and food pictures. Their reaction time (RT) in milliseconds was measured for identifying whether the pairs matched (congruent), or didn't match (incongruent) the associations they'd learnt previously. This test was carried out with, and without, a secondary task. In the secondary task, the participant had to verbally rate how much they liked pictures of faces. All participants completed all conditions, so we have a fully between subjects design, with factors congruency (congruent, incongruent) and load (load, no load).

We start by loading the data and keeping only the test trials.

```{r w-pointline-2-preproc, message=FALSE}
raw <- read_csv('case-studies/chris-mitchell/priming-faces.csv')
priming <- raw %>%
  filter(Running == 'Test') %>%
  group_by(Subject, Congruency, Load) %>%
  summarise(RT = mean(RT, na.rm = TRUE))
```

This type of design is one of the most common in cognitive psychology, and there is a standard way to plot this type of data. We use points to represent our sample means for the RT in each of the four conditions.

```{r w-pointline-2-1, class.source = 'numberLines lineAnchors'}
dodge <- .1
within_2x2 <- priming %>%
  ggplot(aes(x=Congruency, y=RT, group=Load, colour=Load))
within_2x2 <- within_2x2 +
  stat_summary(geom="point", fun=mean,
               position = position_dodge(width = dodge)) +
  stat_summary(geom="line", fun=mean,
               position = position_dodge(width = dodge))
within_2x2
```

### Explanation of commands

Line 1 defines a value that we'll use repeatedly in this worksheet. It will be used adjust the horizontal position of elements, so they don't overlap, making the plot clearer. Line 2-3 define the x axis of our plot to be the Congruency factor, the y axis to be RT, to group Congruency by Load, and to use a different colour for the factor levels `Load`, and `NoLoad`.

Lines 4-6 add mean points to the plot using `stat_summary()`. `stat_summary()` is a concise way to summarise and plot graphical elements. It works in a similar way to the `group_by()` and `summarise()` pattern you've used to create summary statistics. The `fun=mean` tells `stat_summary()` to summarise the data by running the `mean` function for the grouped data you defined in `aes()`. Here, it will calculate a mean RT (`y=RT`) for each of the groups created by `x=Congruency` and `group=Load`. `geom="point"` tells `stat_summary()` to plot the means as points. `position = position_dodge(width = dodge)` specifies an offset to use so that the points won't be plotted on top of each other. Lines 7-8 use a similar approach to add lines to the plot, with endpoints positioned at the four mean points.

Finally, we apply some formatting to the graph.

```{r w-pointline-2-3, message=FALSE, class.source = 'numberLines lineAnchors'}
within_2x2 +
  ylab("Mean RT") + xlab("Congruency") +
  scale_color_grey() + theme_APA
```

### Explanation of commands

Line 2 adds meaningful labels to the axes. Line 3 converts the colours to a grey pallete, and applies our APA theme.
 
### Explanation of plot

The black line is well above the grey line, showing that people were slower to respond on trials where they were rating faces. The average of the black and grey points for congruent is about 625ms, and for incongruent about 640ms. This means that RTs were similar, regardless of the congruencey between the screen colour and food picture.

The congruency effect is the difference between incongruent and congruent trials in ms. In this experiment, we're most interested in how much smaller the congruency effect is under cognitive load. We can calculate this in a similar way to the example in the [Within-subject differences](anova1.html) worksheet.

```{r w_diffdiff, class.source = 'numberLines lineAnchors'}
priming_diff <- priming %>%
  pivot_wider(names_from = c(Congruency, Load), values_from = RT) %>%
  mutate(diff = (Incongruent_NoLoad - Congruent_NoLoad) -
           (Incongruent_Load - Congruent_Load))
```

### Explanation of commands

Lines 1-2 pivot the data into a wide format so we can calculate the 'difference of differences'. For each participant, lines 3-4 calculate the congruency effect under load `(Incongruent_Load - Congruent_Load)` and no load `(Incongruent_NoLoad - Congruent_NoLoad)`, then subtract the no load difference from the load difference.

Again, we can visualise this using a density plot. The only additional command is `scale_x_continuous(n.breaks = 10)` which puts 10 'ticks' on the x axis, in this case, at every 200 ms.

```{r w_diff_plot}
priming_diff %>% ggplot(aes(diff)) +
  geom_density(aes(y=..scaled..)) +
  scale_x_continuous(n.breaks = 10) +
  geom_vline(xintercept = 0, colour = 'red') +
  xlab("Congruency effect: No Load - Load RT (ms)") +
  labs(caption = "Congruency effect = Incongruent - Congruent") +
  ylab("Scaled density") +
  theme_APA
```

### Explanation of plot

The vertical line allows us to quickly see that the density is about the same 
either side of zero. In other words, there's no difference in the congruency effect under load. On average, there's no difference between incongruent and congruent trials, regardless of load, although the range is anything from around -400 to +1450 milliseconds.

<a name="between"></a>

# Between participants data

We now look at some graphs for between participants data.

<a name="b-1x2"></a>

## One factor, two levels

We'll plot some data from [a study in which tested children’s language development](cs-picture-naming.html). The Words in Game (WinG) task uses picture cards to test children's comprehension of, and ability to say, nouns and predicates. A predicate completes an idea about the subject of a sentence. For example, if the card showed a girl pushing a bike, the predicate would be "pushing".

In this study children were tested using one of two sets of picture cards; the set used in the Italian version of WinG, or the set used in the English version. The researchers were primarily interested in whether the children's performance differed depending on which cards were used. We can demonstrate this with plots that show the distribution of scores for the two card sets on the WinG tasks.

We start by preparing the data for plotting. These steps are described in detail in the [Better tables worksheet](better-tables.html) worksheet, so we won’t repeat the description here. Instead, we’ll just list the commands and show the final output.

```{r message=FALSE, class.source = 'numberLines lineAnchors'}
wing_preproc <- read_csv('going-further/picture-naming-preproc.csv')
wing <- wing_preproc %>%
  pivot_longer(cols = c(nc, np, pc, pp),
               names_to = 'task',
               values_to = 'correct') %>%
    select(subj, task, cards, correct)
task_names <- c(
  nc = 'Noun Comprehension',
  np = 'Noun Production',
  pc = 'Predicate Comprehension',
  pp = 'Predicate Production'  
)
wing$task <- wing$task %>% recode(!!!task_names)
wing %>% head(8) %>% pander()
```

We'll plot the data using 'half violin' plots. As the name suggests, this shows one half of a [violin plot](https://en.wikipedia.org/wiki/Violin_plot).

```{r cloud, class.source = 'numberLines lineAnchors'}
# between subjects half-violin plot
library(see)
wing %>% ggplot(aes(x = task, y = correct, fill = cards)) +
  geom_violinhalf(position = position_identity(), alpha=0.7, size=0) +
  xlab('WinG Task') + ylab('Accuracy (max = 20)') +
  scale_fill_grey() + theme_APA +
  theme(axis.text = element_text(size = 10))
```

### Explanation of commands

Line 2 loads the `see` package which provides the `half_violin()` function. Line 3 defines the x axis of our plot to be the WinG `task`, the y axis to be task accuracy (`correct`), and to use the `cards` factor for the fill colour. Line 4 creates a the half violin plots. `position = position_identity()` plots the two distributions on top of each other, making it easy to see how much they overlap. `alpha=0.7` changes the transparency, again to help us see the overlapping area. `size=0` removes the outline around the distributions. Line 5 gives our axes meaningful labels. Line 6 converts the fill colours to a grey pallete, and applies our APA theme. Line 7 adjusts the size of the text on the x axis, so that the task names don't overlap.

### Explanation of plot

The plot gives a visual indication of whether there were differences between the Italian and English cards on each of the tests. Given the extensive overlap in scores between the card sets, this seems unlikely.

### Why not a bar plot?

We could have used a bar plot to graph this data, but the half violin plot seemed a better choice. For example, [Newman & Scholl (2012)](https://link.springer.com/article/10.3758%2Fs13423-012-0247-5) showed that readers misinterpret bar plots, because the values within the bar are perceived as more likely than those just above, even though this is not the case.

For completeness, here's the same data plotted using bars and confidence intervals. As you can see, the code is similar to the point and line plot above.

```{r}
wing %>% ggplot(aes(x=task, y=correct, fill=cards)) +
  stat_summary(geom="bar", fun=mean, position=position_dodge(0.95)) +
  stat_summary(geom="errorbar", width = dodge, fun.data=mean_cl_boot,
               position=position_dodge(0.95)) +
  ylab("Mean RT") + xlab("Congruency") +
  labs(caption = "Bars are 95% confidence intervals") +
  theme_APA + scale_fill_grey() +
  theme(axis.text = element_text(size = 10))
```

<a name="b-1x4"></a>

## One factor, four levels

Another common plot is the boxplot. This includes a thick line which represents the median, and a box on either side which shows how the middle 50% of the data is distributed around the median. The areas above and below the median are called the the upper and lower quartiles respectively. Together they form the 'inter-quartile range' (IQR). The 'whiskers' above and below the quartiles represent the distribution of the top and bottom 25% of the data. The dots draw attention to data points which lie outside of these ranges.

We'll create a boxplot to compare the emotional avoidance strategies for fans of Mainstream (control group), Goth, Metal and Emo music. This data came from a final year undergraduate student dissertation.

```{r avoidance, class.source = 'numberLines lineAnchors', message=FALSE}
ers_l <- read_csv('going-further/music-emotion-preproc.csv')
ers_l <- ers_l %>%
  mutate(subculture = factor(subculture,
                             levels = c('Mainstream', 'Emo', 'Goth', 'Metal')))
avoidance <- ers_l %>% filter(ers == 'avoidance')

avoidance %>% ggplot(aes(x=subculture, y=score)) +
  geom_boxplot() +
  ylab("Emotional avoidance score") + xlab("Music subculture") +
  theme_APA
```

### Explanation of commands

Line 1 loads the data. Lines 3-4 convert subculture to a factor. We use the `levels=` option to order the factor levels, making `Mainstream` first as this group was a control condition. This will make it appear on the left of our plots, so it's easy to compare against the other three subcultures. Line 5 filters out everything except the measure of emotional avoidance. Line 7 puts the avoidance `score` on the y axis and the `subculture` factor on the x axis. Line 8 creates the boxplot with its default settings. Line 9 gives the axes meaningful labels, and line 10 applies our APA theme. 

### Explanation of plot

The medians in all groups are towards the upper end of the scale. The extensive overlap between the boxes and whiskers suggests there weren't any differences between the groups. In all of the groups, a few scores fell beyond the bottom 25% of the distribution.

<a name="mixed"></a>

# Mixed (within-between) data

Mixed designs include both within-subject and between-subject variance. The main challenge here is deciding which source of variance is most useful to represent in your graph. We'll demonstrate some options using data from the student project we used earlier. This was an experiment which compared participants' emotions, before and after they listened to their preferred type of music.

```{r m-load, message=FALSE}
panas <- read_csv('going-further/music-panas.csv')
panas %>% head() %>% pander()
```

There were four groups: fans of Mainstream (control), Goth, Metal and Emo music. So the repeated measure was time (before and after listening to music), and the between-participants factor was music subculture. Emotion was measured using the 20-item Positive and Negative Affect Schedule (PANAS).

This data is in wide format, with one row per participant. We'll focus on negative affect (NA), which is in the columns `pre_na`, and `post_na`. We start bar preparing the data for our graph.
 
```{r m-pointline-1, class.source = 'numberLines lineAnchors'}
panas <- panas %>%
  mutate(subculture = factor(subculture, levels = c('Mainstream', 'Emo', 'Goth', 'Metal')))
na <- panas %>%
  pivot_longer(cols = c(pre_na, post_na),
               names_to = 'pre_post',
               values_to = 'score')
```

### Explanation of commands

Lines 1-2 make `subculture` a factor, and order the factor levels as before, so that our control condition, `Mainstream` will be on the left. The remaining lines convert the negative affect columns to long format, with a factor `pre_post` to identify when the measurement was taken. 

Was negative affect lower in any of the groups after they listened to music? We can represent this by plotting the means and the variance for the two NA measurements. As mentioned in the [More on t-tests](more-on-t.html) worksheet, when comparing two means, the 95% confidence interval is the only thing that is both useful and easy to interpret. So we'll represent the variance using error bars which represent the 95% confidence interval of each mean.

```{r point, class.source = 'numberLines lineAnchors'}
na %>%
  ggplot(aes(x=subculture, y=score, colour = pre_post, group = pre_post)) +
  stat_summary(geom="point", fun=mean, position = position_dodge(width = dodge)) +
  stat_summary(geom="errorbar", width = dodge, fun.data=mean_cl_boot,
               position = position_dodge(width = dodge)) +
  ylab("NA") + xlab("Subculture") +
  scale_color_grey() + theme_APA +
  labs(caption = "Bars are 95% confidence intervals of within-group means")
```

### Explanation of commands

Lines 1-3 plot the mean points, following the same pattern as the [two factor within subjects plot](w-2x2).

Lines 4-5 add the confidence intervals to the plot. Confidence intervals are the same size on either side of the mean. To plot the bars, `ggplot()` needs information about the two sides of the interval. One approach is to write some code to calculate the interval, then pass this data to `ggplot()` to plot the lines. However, we can do this more concisely using `stat_summary()`. The option `fun.data=` is used to specify a function that returns a `y` value, and values `ymax` and `ymin` which specify an interval above and below `y`. We use the function `mean_cl_boot` to calculate a mean of `y`, and the associated confidence interval in `ymax` and `ymin`for our grouped data. The confidence interval is calculated for the factor specified by `group=` in line 2, in this case `pre_post`. `mean_cl_boot` calculates confidence intervals using [bootstrapping](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)), which improves the interval estimate for data which isn't normally distributed.

Line 8 adds a caption, which is essential to let the reader know what the error bars represent. 

### Explanation of plot

In all groups, NA was lower after the participants listening to their preferred type of music. The non-overlapping confidence intervals for Emo suggest that this is the only group where we'll find evidence that music reduces negative affect.

Were there any differences in the effects of music on NA between groups? We can see this by plotting a difference score.

```{r m-diff, class.source = 'numberLines lineAnchors'}
na_diff <- panas %>% mutate(diff = pre_na - post_na)
na_diff %>%
  ggplot(aes(x=subculture, y=diff)) +
  stat_summary(geom="point", fun=mean) +
  stat_summary(geom="errorbar", width = dodge, fun.data=mean_cl_boot) +
  ylab("NA difference") + xlab("Subculture") +
  labs(caption = "Bars are 95% confidence intervals of pre-post mean difference") +
  theme_APA
```

### Explanation of commands

Line 1 calculates the difference in NA after listening to music (`post_na`) by subtracting it from the baseline score (`pre_na`). Line 5 calculates a between groups confidence interval for the difference scores. The remaining lines should be familiar by now.

### Explanation of plot

The largest change was in the Emo group, the smallest was in the Metal group. The only difference appears to be between the Mainstream and Emo groups.

See [Masson & Loftus (2003)](http://personal.psu.edu/jxb14/M554/articles/Masson&Loftus2003.pdf) for a more in-depth discussion about calculating and plotting confidence intervals for within subjects, betweeen subjects, and mixed designs.

<a name="pairs"></a>

## Pairs plot

Like the correlation matrices introduced in the [Better tables](better-tables.html#cor-matrix) worksheet, we can use a 'pairs' plot to show relationships between pairs of variables.

In this plot, a set of variables are listed along the columns, and also down the rows. A pair is the cell defined by a particular row and column. Along the diagonal, variables are paired with themselves, so the correlation doesn't provide any information, as it is always 1. Above the diagonal are all of the combinations of the remaining pairs of variables. The same combinations of pairs are repated below the diagonal.

This format provides an opportunity to provide a lot of information in a small area. In this plot, we'll use some different ways of showing associations between variables, all of which will be familiar from other worksheets. In the upper part of the grid, we'll plot a [correlation coefficient](corr.html) for each pair. For the pairs in the lower part of the grid, we'll create a [scatterplot with a line of best fit](https://benwhalley.github.io/rmip/automatic-line-fitting.html). Along the diagonal, we'll create a [density plot](corr.html#sum), to show the variability for each variable.

We'll plot some data from another undergraduate dissertation. This study was interested in correlations between creative problem solving, and three other variables:

  * problems - number of problems solved
  * Openness - a common factor used in personality research
  * PsiQ - vividness of mental imagery
  * FTT - the score on a flexible thinking task

```{r pairs-2, class.source = 'numberLines lineAnchors', message=FALSE}
library(GGally, quietly = TRUE)
oit <- read_csv('going-further/openness-imagery-thinking.csv')

oit %>%
  select(psiq, openness, problems, ftt) %>%
  ggpairs(lower=list(continuous='smooth')) +
  theme_APA
```

### Explanation of commands

Line 1 loads the `GGally` package, which provides the `ggpairs()` function for creating a pairs plot. Line 2 loads the data. Line 5 selects the variables to compare. Line 6 creates the plot. For the upper area and diagaonal, we don't need to tell `ggpairs()` what to display, as the defaults are exactly what we want. This gives us a Pearson correlation coefficient for each pair above the diaganol, and a density plot for each of the four variables along the diaganol. The option `lower=list(continuous='smooth')`, tells `ggplot()` to create a scatterplot with a best-fit line for each pair in the lower area of the grid. The dots are the individual data points, the black line is the line of best fit. The grey area shows [the standard error of the line of best fit](https://benwhalley.github.io/rmip/explanations-regression.html#explanation-shaded-area-geom-smooth).

### Explanation of plot

There are small positive correlations between FTT and all other variables, and between PsiQ and Openness. There is no correlation between problems solved and either PSiQ or Openness.

The PsiQ density plot shows that nobody scored less than about 3.5, and above that value the data was normally distributed. The pattern was similar for Openness and FTT, with fewer low scores shifting the distribution slightly to the right. The number of problems solved showed the opposite pattern. There was a steady decline from people who solved only one problem, and nobody solved more than four.

Notice that the limits on the x and y scales of the density plots and scatterplots are set by the range of the data rather than the range of the scale. To keep this example simple, we haven't corrected this. For a journal article, you would use ggplot's scale adjustment functions to set the correct x and y limits for each pair.

___

This material is distributed under a [Creative Commons](https://creativecommons.org/) licence. CC-BY-SA 4.0. 


